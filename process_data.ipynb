{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample tokenized inputs:\n",
      "{'input_ids': [13807, 13145, 12388, 16175, 18656, 18627, 21189, 15900, 20617, 19125]}\n",
      "\n",
      "Labeled Data with Binary Events:\n",
      "      id Home_Masked Away_Masked  Excitement_Score Excitement_Label\n",
      "0  93323      Team_3     Team_19                 3         Exciting\n",
      "1  93336     Team_13     Team_15                 1           Normal\n",
      "2  93343      Team_4      Team_8                 1           Normal\n",
      "3  93344      Team_5     Team_19                 1           Normal\n",
      "4  93347      Team_9     Team_20                 1           Normal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"23_24_match_details.csv\", sep=\",\")\n",
    "\n",
    "# Define comprehensive team name variations\n",
    "team_variations = {\n",
    "    \"Team_1\": [\"Arsenal\"],\n",
    "    \"Team_2\": [\"Aston Villa\"],\n",
    "    \"Team_3\": [\"Bournemouth\"],\n",
    "    \"Team_4\": [\"Brentford\"],\n",
    "    \"Team_5\": [\"Brighton & Hove Albion\", \"Brighton\"],\n",
    "    \"Team_6\": [\"Burnley\"],\n",
    "    \"Team_7\": [\"Chelsea\"],\n",
    "    \"Team_8\": [\"Crystal Palace\"],\n",
    "    \"Team_9\": [\"Everton\"],\n",
    "    \"Team_10\": [\"Fulham\"],\n",
    "    \"Team_11\": [\"Liverpool\"],\n",
    "    \"Team_12\": [\"Luton Town\"],\n",
    "    \"Team_13\": [\"Manchester City\", \"Man City\"],\n",
    "    \"Team_14\": [\"Manchester United\"],\n",
    "    \"Team_15\": [\"Newcastle United\", \"Newcastle\"],\n",
    "    \"Team_16\": [\"Nottingham Forest\"],\n",
    "    \"Team_17\": [\"Sheffield United\"],\n",
    "    \"Team_18\": [\"Tottenham Hotspur\", \"Tottenham\"],\n",
    "    \"Team_19\": [\"West Ham United\", \"West Ham\"],\n",
    "    \"Team_20\": [\"Wolves\"],\n",
    "}\n",
    "\n",
    "# Create a reverse mapping dictionary with lowercase keys for case-insensitive matching\n",
    "mask_mapping = {}\n",
    "for team_label, variations in team_variations.items():\n",
    "    for name in variations:\n",
    "        mask_mapping[name.lower()] = team_label\n",
    "\n",
    "# Function to replace team names in text with their masked counterparts\n",
    "def mask_teams(text, mapping):\n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    sorted_teams = sorted(mapping.keys(), key=len, reverse=True)\n",
    "    for team in sorted_teams:\n",
    "        pattern = r\"\\b\" + re.escape(team) + r\"(?:'s)?\\b\"\n",
    "        replacement = mapping[team]\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "# Apply masking to 'Home' and 'Away' columns\n",
    "if \"Home\" in df.columns:\n",
    "    df[\"Home_Masked\"] = df[\"Home\"].str.lower().map(mask_mapping)\n",
    "else:\n",
    "    df[\"Home_Masked\"] = np.nan\n",
    "\n",
    "if \"Away\" in df.columns:\n",
    "    df[\"Away_Masked\"] = df[\"Away\"].str.lower().map(mask_mapping)\n",
    "else:\n",
    "    df[\"Away_Masked\"] = np.nan\n",
    "\n",
    "# Apply masking to 'events' and 'summary' columns\n",
    "if \"events\" in df.columns:\n",
    "    df[\"text_Masked\"] = df[\"events\"].apply(lambda x: mask_teams(x, mask_mapping))\n",
    "else:\n",
    "    df[\"text_Masked\"] = np.nan\n",
    "\n",
    "# Define binary event functions\n",
    "def red_card_followed_by_goal(text):\n",
    "    \"\"\"Check if there was a red card followed by a goal.\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"red card.*?goal\", text, re.IGNORECASE | re.DOTALL):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def last_minute_goal(text):\n",
    "    \"\"\"Check if a goal was scored in the last minute or extra time.\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"goal.*?(90'|extra time)\", text, re.IGNORECASE):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def comeback_attempt(text):\n",
    "    \"\"\"Check if there was an attempt to come back (team scores after being down).\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"down.*?goal\", text, re.IGNORECASE | re.DOTALL):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def var_review_red_card(text):\n",
    "    \"\"\"Check if a VAR review led to a red card.\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"VAR review.*?red card\", text, re.IGNORECASE | re.DOTALL):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def hat_trick(text):\n",
    "    \"\"\"Check if there was a hat-trick.\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"hat[- ]trick\", text, re.IGNORECASE):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def penalty_drama(text):\n",
    "    \"\"\"Check if there was a missed or contested penalty.\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"penalty.*?(missed|saved|contested)\", text, re.IGNORECASE):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Apply the binary event functions\n",
    "if \"text_Masked\" in df.columns:\n",
    "    df[\"Red_Card_Followed_By_Goal\"] = df[\"text_Masked\"].apply(red_card_followed_by_goal)\n",
    "    df[\"Last_Minute_Goal\"] = df[\"text_Masked\"].apply(last_minute_goal)\n",
    "    df[\"Comeback_Attempt\"] = df[\"text_Masked\"].apply(comeback_attempt)\n",
    "    df[\"VAR_Review_Red_Card\"] = df[\"text_Masked\"].apply(var_review_red_card)\n",
    "    df[\"Hat_Trick\"] = df[\"text_Masked\"].apply(hat_trick)\n",
    "    df[\"Penalty_Drama\"] = df[\"text_Masked\"].apply(penalty_drama)\n",
    "else:\n",
    "    df[\"Red_Card_Followed_By_Goal\"] = 0\n",
    "    df[\"Last_Minute_Goal\"] = 0\n",
    "    df[\"Comeback_Attempt\"] = 0\n",
    "    df[\"VAR_Review_Red_Card\"] = 0\n",
    "    df[\"Hat_Trick\"] = 0\n",
    "    df[\"Penalty_Drama\"] = 0\n",
    "\n",
    "# Calculate overall excitement score by summing the binary event columns\n",
    "df[\"Excitement_Score\"] = (\n",
    "    df[\"Red_Card_Followed_By_Goal\"] +\n",
    "    df[\"Last_Minute_Goal\"] +\n",
    "    df[\"Comeback_Attempt\"] +\n",
    "    df[\"VAR_Review_Red_Card\"] +\n",
    "    df[\"Hat_Trick\"] +\n",
    "    df[\"Penalty_Drama\"]\n",
    ")\n",
    "\n",
    "# Label excitement level based on score threshold\n",
    "def label_excitement(score):\n",
    "    if score >= 2:\n",
    "        return \"Exciting\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "df[\"Excitement_Label\"] = df[\"Excitement_Score\"].apply(label_excitement)\n",
    "\n",
    "# Ensure all text inputs are strings before passing to tokenizer\n",
    "def preprocess_function(examples):\n",
    "    inputs = [str(x) if x is not None else \"\" for x in examples[\"text\"]]\n",
    "    # Simulate tokenizer call here (you can replace it with your actual tokenizer logic)\n",
    "    tokenized_inputs = {\"input_ids\": [len(input) for input in inputs]}  # Placeholder logic\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Validate preprocessing\n",
    "sample_data = {\"text\": df[\"text_Masked\"].head(10).to_list()}\n",
    "processed_sample = preprocess_function(sample_data)\n",
    "print(\"\\nSample tokenized inputs:\")\n",
    "print(processed_sample)\n",
    "\n",
    "# Display summary of the labeled data\n",
    "print(\"\\nLabeled Data with Binary Events:\")\n",
    "print(df[[\"id\", \"Home_Masked\", \"Away_Masked\", \"Excitement_Score\", \"Excitement_Label\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of Excitement Levels:\n",
      "Training Set:\n",
      "label\n",
      "Normal      0.640496\n",
      "Exciting    0.359504\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation Set:\n",
      "label\n",
      "Normal      0.633333\n",
      "Exciting    0.366667\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test Set:\n",
      "label\n",
      "Normal      0.645161\n",
      "Exciting    0.354839\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Data has been split and saved into the following files:\n",
      "1. Training Data: train_data.tsv\n",
      "2. Validation Data: validation_data.tsv\n",
      "3. Test Data: test_data.tsv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Rename id to textid\n",
    "df.rename(columns={\"id\": \"textid\"}, inplace=True)\n",
    "# Rename text_Masked to text\n",
    "df.rename(columns={\"text_Masked\": \"text\"}, inplace=True)\n",
    "# Rename Excitement_Label to label\n",
    "df.rename(columns={\"Excitement_Label\": \"label\"}, inplace=True)\n",
    "\n",
    "# print(df.head())\n",
    "\n",
    "# Split the data into training (80%) and temp (20%)\n",
    "train_data, temp_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "# Split the temp data into validation (10%) and test (10%)\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data[\"label\"])\n",
    "\n",
    "# Check the distribution of labels in each split\n",
    "print(\"\\nDistribution of Excitement Levels:\")\n",
    "print(\"Training Set:\")\n",
    "print(train_data[\"label\"].value_counts(normalize=True))\n",
    "print(\"\\nValidation Set:\")\n",
    "print(validation_data[\"label\"].value_counts(normalize=True))\n",
    "print(\"\\nTest Set:\")\n",
    "print(test_data[\"label\"].value_counts(normalize=True))\n",
    "\n",
    "# Save each split to separate files\n",
    "train_data.to_csv(\"train_data.tsv\", sep=\"\\t\", index=False)\n",
    "validation_data.to_csv(\"validation_data.tsv\", sep=\"\\t\", index=False)\n",
    "test_data.to_csv(\"test_data.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"\\nData has been split and saved into the following files:\")\n",
    "print(\"1. Training Data: train_data.tsv\")\n",
    "print(\"2. Validation Data: validation_data.tsv\")\n",
    "print(\"3. Test Data: test_data.tsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
