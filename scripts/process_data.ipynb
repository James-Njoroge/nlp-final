{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of Excitement Levels:\n",
      "Training Set:\n",
      "label\n",
      "Normal      0.640496\n",
      "Exciting    0.359504\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation Set:\n",
      "label\n",
      "Normal      0.633333\n",
      "Exciting    0.366667\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test Set:\n",
      "label\n",
      "Normal      0.645161\n",
      "Exciting    0.354839\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Data has been split and saved into the following files:\n",
      "1. Training Data: train_data.tsv\n",
      "2. Validation Data: validation_data.tsv\n",
      "3. Test Data: test_data.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"23_24_match_details.csv\", sep=\",\")\n",
    "\n",
    "# Define comprehensive team name variations\n",
    "team_variations = {\n",
    "    \"Team_1\": [\"Arsenal\"],\n",
    "    \"Team_2\": [\"Aston Villa\"],\n",
    "    \"Team_3\": [\"Bournemouth\"],\n",
    "    \"Team_4\": [\"Brentford\"],\n",
    "    \"Team_5\": [\"Brighton & Hove Albion\", \"Brighton\"],\n",
    "    \"Team_6\": [\"Burnley\"],\n",
    "    \"Team_7\": [\"Chelsea\"],\n",
    "    \"Team_8\": [\"Crystal Palace\"],\n",
    "    \"Team_9\": [\"Everton\"],\n",
    "    \"Team_10\": [\"Fulham\"],\n",
    "    \"Team_11\": [\"Liverpool\"],\n",
    "    \"Team_12\": [\"Luton Town\"],\n",
    "    \"Team_13\": [\"Manchester City\", \"Man City\"],\n",
    "    \"Team_14\": [\"Manchester United\"],\n",
    "    \"Team_15\": [\"Newcastle United\", \"Newcastle\"],\n",
    "    \"Team_16\": [\"Nottingham Forest\"],\n",
    "    \"Team_17\": [\"Sheffield United\"],\n",
    "    \"Team_18\": [\"Tottenham Hotspur\", \"Tottenham\"],\n",
    "    \"Team_19\": [\"West Ham United\", \"West Ham\"],\n",
    "    \"Team_20\": [\"Wolves\"],\n",
    "}\n",
    "\n",
    "# Create a reverse mapping dictionary with lowercase keys for case-insensitive matching\n",
    "mask_mapping = {}\n",
    "for team_label, variations in team_variations.items():\n",
    "    for name in variations:\n",
    "        mask_mapping[name.lower()] = team_label\n",
    "\n",
    "# Function to replace team names in text with their masked counterparts\n",
    "def mask_teams(text, mapping):\n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    sorted_teams = sorted(mapping.keys(), key=len, reverse=True)\n",
    "    for team in sorted_teams:\n",
    "        pattern = r\"\\b\" + re.escape(team) + r\"(?:'s)?\\b\"\n",
    "        replacement = mapping[team]\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "# Apply masking to 'Home' and 'Away' columns\n",
    "if \"Home\" in df.columns:\n",
    "    df[\"Home_Masked\"] = df[\"Home\"].str.lower().map(mask_mapping)\n",
    "else:\n",
    "    df[\"Home_Masked\"] = np.nan\n",
    "\n",
    "if \"Away\" in df.columns:\n",
    "    df[\"Away_Masked\"] = df[\"Away\"].str.lower().map(mask_mapping)\n",
    "else:\n",
    "    df[\"Away_Masked\"] = np.nan\n",
    "\n",
    "# Apply masking to 'events' and 'summary' columns\n",
    "if \"events\" in df.columns:\n",
    "    df[\"text_Masked\"] = df[\"events\"].apply(lambda x: mask_teams(x, mask_mapping))\n",
    "else:\n",
    "    df[\"text_Masked\"] = np.nan\n",
    "\n",
    "# Define binary event functions\n",
    "def red_card_followed_by_goal(text):\n",
    "    \"\"\"Check if there was a red card followed by a goal.\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"red card.*?goal\", text, re.IGNORECASE | re.DOTALL):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def last_minute_goal(text):\n",
    "    \"\"\"Check if a goal was scored in the last minute or extra time.\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"goal.*?(90'|extra time)\", text, re.IGNORECASE):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def comeback_attempt(text):\n",
    "    \"\"\"Check if there was an attempt to come back (team scores after being down).\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"down.*?goal\", text, re.IGNORECASE | re.DOTALL):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def var_review_red_card(text):\n",
    "    \"\"\"Check if a VAR review led to a red card.\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"VAR review.*?red card\", text, re.IGNORECASE | re.DOTALL):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def hat_trick(text):\n",
    "    \"\"\"Check if there was a hat-trick.\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"hat[- ]trick\", text, re.IGNORECASE):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def penalty_drama(text):\n",
    "    \"\"\"Check if there was a missed or contested penalty.\"\"\"\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"penalty.*?(missed|saved|contested)\", text, re.IGNORECASE):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Apply the binary event functions\n",
    "if \"text_Masked\" in df.columns:\n",
    "    df[\"Red_Card_Followed_By_Goal\"] = df[\"text_Masked\"].apply(red_card_followed_by_goal)\n",
    "    df[\"Last_Minute_Goal\"] = df[\"text_Masked\"].apply(last_minute_goal)\n",
    "    df[\"Comeback_Attempt\"] = df[\"text_Masked\"].apply(comeback_attempt)\n",
    "    df[\"VAR_Review_Red_Card\"] = df[\"text_Masked\"].apply(var_review_red_card)\n",
    "    df[\"Hat_Trick\"] = df[\"text_Masked\"].apply(hat_trick)\n",
    "    df[\"Penalty_Drama\"] = df[\"text_Masked\"].apply(penalty_drama)\n",
    "else:\n",
    "    df[\"Red_Card_Followed_By_Goal\"] = 0\n",
    "    df[\"Last_Minute_Goal\"] = 0\n",
    "    df[\"Comeback_Attempt\"] = 0\n",
    "    df[\"VAR_Review_Red_Card\"] = 0\n",
    "    df[\"Hat_Trick\"] = 0\n",
    "    df[\"Penalty_Drama\"] = 0\n",
    "\n",
    "# Calculate overall excitement score by summing the binary event columns\n",
    "df[\"Excitement_Score\"] = (\n",
    "    df[\"Red_Card_Followed_By_Goal\"] +\n",
    "    df[\"Last_Minute_Goal\"] +\n",
    "    df[\"Comeback_Attempt\"] +\n",
    "    df[\"VAR_Review_Red_Card\"] +\n",
    "    df[\"Hat_Trick\"] +\n",
    "    df[\"Penalty_Drama\"]\n",
    ")\n",
    "\n",
    "# Label excitement level based on score threshold\n",
    "def label_excitement(score):\n",
    "    if score >= 2:\n",
    "        return \"Exciting\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "df[\"Excitement_Label\"] = df[\"Excitement_Score\"].apply(label_excitement)\n",
    "\n",
    "# Rename columns to prepare for tokenization and processing\n",
    "df.rename(columns={\"id\": \"textid\", \"text_Masked\": \"text\", \"Excitement_Label\": \"label\"}, inplace=True)\n",
    "\n",
    "# Ensure all text inputs are strings and create nested list structure\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)  # Ensure all text is string\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: [x])  # Convert to nested list format\n",
    "\n",
    "# Split the data into training (80%) and temp (20%)\n",
    "train_data, temp_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "# Split the temp data into validation (10%) and test (10%)\n",
    "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data[\"label\"])\n",
    "\n",
    "# Check the distribution of labels in each split\n",
    "print(\"\\nDistribution of Excitement Levels:\")\n",
    "print(\"Training Set:\")\n",
    "print(train_data[\"label\"].value_counts(normalize=True))\n",
    "print(\"\\nValidation Set:\")\n",
    "print(validation_data[\"label\"].value_counts(normalize=True))\n",
    "print(\"\\nTest Set:\")\n",
    "print(test_data[\"label\"].value_counts(normalize=True))\n",
    "\n",
    "# Save each split to separate files\n",
    "train_data.to_csv(\"train_data.tsv\", sep=\"\\t\", index=False)\n",
    "validation_data.to_csv(\"validation_data.tsv\", sep=\"\\t\", index=False)\n",
    "test_data.to_csv(\"test_data.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"\\nData has been split and saved into the following files:\")\n",
    "print(\"1. Training Data: train_data.tsv\")\n",
    "print(\"2. Validation Data: validation_data.tsv\")\n",
    "print(\"3. Test Data: test_data.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting completed. Output saved to 'split_comm_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Load the data\n",
    "input_file = '../data/clean_comm_data.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Define comprehensive team name variations\n",
    "team_variations = {\n",
    "    \"Team_1\": [\"Arsenal\", \"Gunners\"],\n",
    "    \"Team_2\": [\"Aston Villa\", \"Villa\", \"Villans\", \"The Lions\", \"Claret and Blue Army\"],\n",
    "    \"Team_3\": [\"Bournemouth\", \"Cherries\"],\n",
    "    \"Team_4\": [\"Brentford\", \"Bees\"],\n",
    "    \"Team_5\": [\"Brighton & Hove Albion\", \"Brighton\", \"Seagulls\", \"Albion\"],\n",
    "    \"Team_6\": [\"Burnley\", \"Clarets\"],\n",
    "    \"Team_7\": [\"Chelsea\", \"Blues\"],\n",
    "    \"Team_8\": [\"Crystal Palace\", \"Eagles\"],\n",
    "    \"Team_9\": [\"Everton\", \"Toffees\"],\n",
    "    \"Team_10\": [\"Fulham\", \"The Cottagers\", \"Whites\", \"Lily Whites\"],\n",
    "    \"Team_11\": [\"Liverpool\", \"Reds\"],\n",
    "    \"Team_12\": [\"Luton Town\", \"Hatters\"],\n",
    "    \"Team_13\": [\"Manchester City\", \"Man City\", \"City\", \"Citizens\", \"Sky Blues\"],\n",
    "    \"Team_14\": [\"Manchester United\", \"Man United\", \"Man U\", \"Red Devils\", \"United\"],\n",
    "    \"Team_15\": [\"Newcastle United\", \"Newcastle\", \"Magpies\", \"Geordies\"],\n",
    "    \"Team_16\": [\"Nottingham Forest\", \"Forest\", \"Reds\", \"Tricky Trees\", \"Garibaldi\"],\n",
    "    \"Team_17\": [\"Sheffield United\", \"Blades\"],\n",
    "    \"Team_18\": [\"Tottenham Hotspur\", \"Tottenham\", \"Spurs\", \"Lilywhites\"],\n",
    "    \"Team_19\": [\"West Ham United\", \"West Ham\", \"Hammers\", \"Irons\"],\n",
    "    \"Team_20\": [\"Wolves\", \"Wolverhampton Wanderers\", \"Wanderers\"]\n",
    "}\n",
    "\n",
    "# Create a reverse mapping dictionary with lowercase keys for case-insensitive matching\n",
    "mask_mapping = {}\n",
    "for team_label, variations in team_variations.items():\n",
    "    for name in variations:\n",
    "        mask_mapping[name.lower()] = team_label\n",
    "\n",
    "# Function to replace team names in text with their masked counterparts\n",
    "def mask_teams(text, mapping):\n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    sorted_teams = sorted(mapping.keys(), key=len, reverse=True)\n",
    "    for team in sorted_teams:\n",
    "        pattern = r\"\\b\" + re.escape(team) + r\"(?:'s)?\\b\"\n",
    "        replacement = mapping[team]\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "# Apply masking to 'Home' and 'Away' columns\n",
    "if \"Home\" in df.columns:\n",
    "    df[\"Home_Masked\"] = df[\"Home\"].str.lower().map(mask_mapping)\n",
    "else:\n",
    "    df[\"Home_Masked\"] = np.nan\n",
    "\n",
    "if \"Away\" in df.columns:\n",
    "    df[\"Away_Masked\"] = df[\"Away\"].str.lower().map(mask_mapping)\n",
    "else:\n",
    "    df[\"Away_Masked\"] = np.nan\n",
    "\n",
    "# Apply masking to 'events' and 'summary' columns\n",
    "if \"events\" in df.columns:\n",
    "    df[\"text_Masked\"] = df[\"events\"].apply(lambda x: mask_teams(x, mask_mapping))\n",
    "else:\n",
    "    df[\"text_Masked\"] = np.nan\n",
    "\n",
    "# Define binary event functions\n",
    "def red_card_followed_by_goal(text):\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"red card.*?goal\", text, re.IGNORECASE | re.DOTALL):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def last_minute_goal(text):\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"goal.*?(90'|extra time)\", text, re.IGNORECASE):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def comeback_attempt(text):\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"down.*?goal\", text, re.IGNORECASE | re.DOTALL):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def var_review_red_card(text):\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"VAR review.*?red card\", text, re.IGNORECASE | re.DOTALL):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def hat_trick(text):\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"hat[- ]trick\", text, re.IGNORECASE):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def penalty_drama(text):\n",
    "    if pd.isnull(text): return 0\n",
    "    if re.search(r\"penalty.*?(missed|saved|contested)\", text, re.IGNORECASE):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Apply the binary event functions\n",
    "if \"text_Masked\" in df.columns:\n",
    "    df[\"Red_Card_Followed_By_Goal\"] = df[\"text_Masked\"].apply(red_card_followed_by_goal)\n",
    "    df[\"Last_Minute_Goal\"] = df[\"text_Masked\"].apply(last_minute_goal)\n",
    "    df[\"Comeback_Attempt\"] = df[\"text_Masked\"].apply(comeback_attempt)\n",
    "    df[\"VAR_Review_Red_Card\"] = df[\"text_Masked\"].apply(var_review_red_card)\n",
    "    df[\"Hat_Trick\"] = df[\"text_Masked\"].apply(hat_trick)\n",
    "    df[\"Penalty_Drama\"] = df[\"text_Masked\"].apply(penalty_drama)\n",
    "else:\n",
    "    df[\"Red_Card_Followed_By_Goal\"] = 0\n",
    "    df[\"Last_Minute_Goal\"] = 0\n",
    "    df[\"Comeback_Attempt\"] = 0\n",
    "    df[\"VAR_Review_Red_Card\"] = 0\n",
    "    df[\"Hat_Trick\"] = 0\n",
    "    df[\"Penalty_Drama\"] = 0\n",
    "\n",
    "# Calculate overall excitement score by summing the binary event columns\n",
    "df[\"Excitement_Score\"] = (\n",
    "    df[\"Red_Card_Followed_By_Goal\"] +\n",
    "    df[\"Last_Minute_Goal\"] +\n",
    "    df[\"Comeback_Attempt\"] +\n",
    "    df[\"VAR_Review_Red_Card\"] +\n",
    "    df[\"Hat_Trick\"] +\n",
    "    df[\"Penalty_Drama\"]\n",
    ")\n",
    "\n",
    "# Label excitement level based on score threshold\n",
    "def label_excitement(score):\n",
    "    if score >= 2:\n",
    "        return \"Exciting\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "df[\"Excitement_Label\"] = df[\"Excitement_Score\"].apply(label_excitement)\n",
    "\n",
    "# Rename columns to prepare for tokenization and processing\n",
    "df.rename(columns={\"id\": \"textid\", \"text_Masked\": \"text\", \"Excitement_Label\": \"label\"}, inplace=True)\n",
    "\n",
    "# Ensure all text inputs are strings\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)  # Ensure all text is string\n",
    "\n",
    "# Define the function to split text\n",
    "# Assumption: The dataframe has columns 'textid' and 'text'\n",
    "# For rows where 'text' has more than 400 words, split it into multiple rows\n",
    "def split_text(row, word_limit=400):\n",
    "    words = row['text'].split()\n",
    "    chunks = [words[i:i + word_limit] for i in range(0, len(words), word_limit)]\n",
    "    result_rows = []\n",
    "    for index, chunk in enumerate(chunks):\n",
    "        result_row = row.copy()\n",
    "        result_row['text'] = ' '.join(chunk)\n",
    "        if index > 0:\n",
    "            result_row['textid'] = f\"{row['textid']}_{index + 1}\"\n",
    "        result_rows.append(result_row)\n",
    "    return result_rows\n",
    "\n",
    "# Create a new dataframe to hold the split rows\n",
    "split_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    split_rows.extend(split_text(row))\n",
    "\n",
    "# Create a new DataFrame\n",
    "new_df = pd.DataFrame(split_rows)\n",
    "\n",
    "# # Save the new DataFrame\n",
    "# output_file = '../data/split_comm_data.csv'\n",
    "# new_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Splitting completed. Output saved to 'split_comm_data.csv'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting into train, validate, and test sets completed. Output saved to respective .tsv files.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train (70%), validation (15%), and test (15%)\n",
    "train_df, temp_df = train_test_split(new_df, test_size=0.3, random_state=42)\n",
    "validate_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save train, validate, and test sets as .tsv files\n",
    "train_df = train_df[['textid', 'text', 'Excitement_Score', 'label']]\n",
    "validate_df = validate_df[['textid', 'text', 'Excitement_Score', 'label']]\n",
    "test_df = test_df[['textid', 'text', 'label']]\n",
    "\n",
    "# Rename columns for test_df and add 'condition' column\n",
    "test_df.rename(columns={'label': 'target'}, inplace=True)\n",
    "test_df['condition'] = 'commentary'\n",
    "\n",
    "# Save the dataframes to .tsv files\n",
    "train_df.to_csv('../data/split_comm_data_train.tsv', sep='\\t', index=False)\n",
    "validate_df.to_csv('../data/split_comm_data_validate.tsv', sep='\\t', index=False)\n",
    "test_df.to_csv('../data/split_comm_data_test.tsv', sep='\\t', index=False)\n",
    "\n",
    "print(\"Data splitting into train, validate, and test sets completed. Output saved to respective .tsv files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
